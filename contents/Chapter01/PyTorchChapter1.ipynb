{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrLt-C4PRV_f",
    "outputId": "93b5119e-505d-4ab5-a3bb-26803d9b517f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "It4yTLaRao7o",
    "outputId": "896ad986-b4bd-4376-ef3d-9575aa9cd807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 34.85592269897461\n",
      "Loss = 27.715070724487305\n",
      "Loss = 22.090993881225586\n",
      "Loss = 17.66036033630371\n",
      "Loss = 14.16879940032959\n",
      "Loss = 11.416169166564941\n",
      "Loss = 9.245010375976562\n",
      "Loss = 7.53143835067749\n",
      "Loss = 6.177985668182373\n",
      "Loss = 5.107965469360352\n",
      "Loss = 4.261043071746826\n",
      "Loss = 3.5897467136383057\n",
      "Loss = 3.0567283630371094\n",
      "Loss = 2.632599353790283\n",
      "Loss = 2.2942373752593994\n",
      "Loss = 2.0234501361846924\n",
      "Loss = 1.8059202432632446\n",
      "Loss = 1.630383014678955\n",
      "Loss = 1.4879741668701172\n",
      "Loss = 1.3717178106307983\n",
      "Loss = 1.276122808456421\n",
      "Loss = 1.1968685388565063\n",
      "Loss = 1.130553126335144\n",
      "Loss = 1.074499249458313\n",
      "Loss = 1.0265977382659912\n",
      "Loss = 0.9851885437965393\n",
      "Loss = 0.9489637017250061\n",
      "Loss = 0.9168922901153564\n",
      "Loss = 0.88816237449646\n",
      "Loss = 0.8621330261230469\n",
      "Loss = 0.838298499584198\n",
      "Loss = 0.8162599205970764\n",
      "Loss = 0.7957015037536621\n",
      "Loss = 0.776374340057373\n",
      "Loss = 0.7580800652503967\n",
      "Loss = 0.740662157535553\n",
      "Loss = 0.7239958643913269\n",
      "Loss = 0.7079815864562988\n",
      "Loss = 0.6925399899482727\n",
      "Loss = 0.6776073575019836\n",
      "Loss = 0.66313236951828\n",
      "Loss = 0.6490731835365295\n",
      "Loss = 0.6353963613510132\n",
      "Loss = 0.6220738291740417\n",
      "Loss = 0.6090827584266663\n",
      "Loss = 0.5964041352272034\n",
      "Loss = 0.5840216279029846\n",
      "Loss = 0.5719216465950012\n",
      "Loss = 0.5600922703742981\n",
      "Loss = 0.5485233664512634\n",
      "Loss = 0.5372057557106018\n",
      "Loss = 0.5261314511299133\n",
      "Loss = 0.5152930021286011\n",
      "Loss = 0.5046840310096741\n",
      "Loss = 0.4942980706691742\n",
      "Loss = 0.4841296672821045\n",
      "Loss = 0.47417333722114563\n",
      "Loss = 0.46442410349845886\n",
      "Loss = 0.454877108335495\n",
      "Loss = 0.44552791118621826\n",
      "Loss = 0.43637189269065857\n",
      "Loss = 0.42740488052368164\n",
      "Loss = 0.4186228811740875\n",
      "Loss = 0.4100218713283539\n",
      "Loss = 0.4015980064868927\n",
      "Loss = 0.39334750175476074\n",
      "Loss = 0.38526690006256104\n",
      "Loss = 0.37735238671302795\n",
      "Loss = 0.36960068345069885\n",
      "Loss = 0.36200833320617676\n",
      "Loss = 0.3545720875263214\n",
      "Loss = 0.347288578748703\n",
      "Loss = 0.3401547968387604\n",
      "Loss = 0.33316758275032043\n",
      "Loss = 0.3263240158557892\n",
      "Loss = 0.3196209967136383\n",
      "Loss = 0.31305572390556335\n",
      "Loss = 0.3066253066062927\n",
      "Loss = 0.300326943397522\n",
      "Loss = 0.2941579520702362\n",
      "Loss = 0.2881157100200653\n",
      "Loss = 0.28219762444496155\n",
      "Loss = 0.2764010429382324\n",
      "Loss = 0.2707235813140869\n",
      "Loss = 0.26516270637512207\n",
      "Loss = 0.25971612334251404\n",
      "Loss = 0.25438132882118225\n",
      "Loss = 0.249156191945076\n",
      "Loss = 0.2440384179353714\n",
      "Loss = 0.23902565240859985\n",
      "Loss = 0.23411589860916138\n",
      "Loss = 0.22930704057216644\n",
      "Loss = 0.22459690272808075\n",
      "Loss = 0.2199835628271103\n",
      "Loss = 0.2154650092124939\n",
      "Loss = 0.21103918552398682\n",
      "Loss = 0.20670436322689056\n",
      "Loss = 0.20245850086212158\n",
      "Loss = 0.19829988479614258\n",
      "Loss = 0.19422662258148193\n",
      "Loss = 0.1902371495962143\n",
      "Loss = 0.18632955849170685\n",
      "Loss = 0.18250228464603424\n",
      "Loss = 0.1787535697221756\n",
      "Loss = 0.17508183419704437\n",
      "Loss = 0.17148558795452118\n",
      "Loss = 0.16796310245990753\n",
      "Loss = 0.16451305150985718\n",
      "Loss = 0.16113390028476715\n",
      "Loss = 0.15782411396503448\n",
      "Loss = 0.15458229184150696\n",
      "Loss = 0.15140709280967712\n",
      "Loss = 0.14829710125923157\n",
      "Loss = 0.14525093138217926\n",
      "Loss = 0.14226742088794708\n",
      "Loss = 0.13934515416622162\n",
      "Loss = 0.13648293912410736\n",
      "Loss = 0.13367949426174164\n",
      "Loss = 0.13093365728855133\n",
      "Loss = 0.12824414670467377\n",
      "Loss = 0.12560999393463135\n",
      "Loss = 0.12302988767623901\n",
      "Loss = 0.12050274759531021\n",
      "Loss = 0.11802756041288376\n",
      "Loss = 0.11560320109128952\n",
      "Loss = 0.1132286787033081\n",
      "Loss = 0.11090286821126938\n",
      "Loss = 0.10862485319375992\n",
      "Loss = 0.10639365762472153\n",
      "Loss = 0.10420819371938705\n",
      "Loss = 0.102067731320858\n",
      "Loss = 0.09997117519378662\n",
      "Loss = 0.09791773557662964\n",
      "Loss = 0.09590644389390945\n",
      "Loss = 0.09393647313117981\n",
      "Loss = 0.09200692921876907\n",
      "Loss = 0.09011704474687576\n",
      "Loss = 0.08826596289873123\n",
      "Loss = 0.08645296841859818\n",
      "Loss = 0.08467715978622437\n",
      "Loss = 0.0829378217458725\n",
      "Loss = 0.08123424649238586\n",
      "Loss = 0.07956559211015701\n",
      "Loss = 0.07793127745389938\n",
      "Loss = 0.07633053511381149\n",
      "Loss = 0.07476267963647842\n",
      "Loss = 0.07322701066732407\n",
      "Loss = 0.07172288745641708\n",
      "Loss = 0.07024965435266495\n",
      "Loss = 0.06880669295787811\n",
      "Loss = 0.06739335507154465\n",
      "Loss = 0.06600900739431381\n",
      "Loss = 0.06465313583612442\n",
      "Loss = 0.0633251741528511\n",
      "Loss = 0.06202441453933716\n",
      "Loss = 0.06075042113661766\n",
      "Loss = 0.05950254201889038\n",
      "Loss = 0.05828035995364189\n",
      "Loss = 0.05708320438861847\n",
      "Loss = 0.05591069161891937\n",
      "Loss = 0.05476222559809685\n",
      "Loss = 0.05363737419247627\n",
      "Loss = 0.052535634487867355\n",
      "Loss = 0.051456551998853683\n",
      "Loss = 0.050399575382471085\n",
      "Loss = 0.0493643544614315\n",
      "Loss = 0.04835037514567375\n",
      "Loss = 0.04735720530152321\n",
      "Loss = 0.046384457498788834\n",
      "Loss = 0.045431699603796005\n",
      "Loss = 0.044498518109321594\n",
      "Loss = 0.04358449950814247\n",
      "Loss = 0.0426892526447773\n",
      "Loss = 0.04181237518787384\n",
      "Loss = 0.04095352068543434\n",
      "Loss = 0.040112294256687164\n",
      "Loss = 0.039288368076086044\n",
      "Loss = 0.03848137706518173\n",
      "Loss = 0.03769095987081528\n",
      "Loss = 0.03691675141453743\n",
      "Loss = 0.03615846112370491\n",
      "Loss = 0.03541574999690056\n",
      "Loss = 0.03468829020857811\n",
      "Loss = 0.03397578001022339\n",
      "Loss = 0.03327789530158043\n",
      "Loss = 0.03259431570768356\n",
      "Loss = 0.03192483261227608\n",
      "Loss = 0.03126907721161842\n",
      "Loss = 0.030626773834228516\n",
      "Loss = 0.029997678473591805\n",
      "Loss = 0.0293815266340971\n",
      "Loss = 0.028777988627552986\n",
      "Loss = 0.028186902403831482\n",
      "Loss = 0.02760792337357998\n",
      "Loss = 0.02704082429409027\n",
      "Loss = 0.02648538537323475\n",
      "Loss = 0.025941377505660057\n",
      "Loss = 0.025408506393432617\n",
      "Loss = 0.02488660253584385\n",
      "Loss = 0.024375414475798607\n",
      "Loss = 0.023874739184975624\n",
      "Loss = 0.023384327068924904\n",
      "Loss = 0.02290399931371212\n",
      "Loss = 0.022433532401919365\n",
      "Loss = 0.02197273261845112\n",
      "Loss = 0.021521389484405518\n",
      "Loss = 0.021079355850815773\n",
      "Loss = 0.020646359771490097\n",
      "Loss = 0.02022227644920349\n",
      "Loss = 0.019806895405054092\n",
      "Loss = 0.01940004900097847\n",
      "Loss = 0.019001564010977745\n",
      "Loss = 0.018611231818795204\n",
      "Loss = 0.01822897046804428\n",
      "Loss = 0.017854517325758934\n",
      "Loss = 0.01748778484761715\n",
      "Loss = 0.017128558829426765\n",
      "Loss = 0.016776734963059425\n",
      "Loss = 0.016432130709290504\n",
      "Loss = 0.01609458215534687\n",
      "Loss = 0.01576400361955166\n",
      "Loss = 0.015440189279615879\n",
      "Loss = 0.015123049728572369\n",
      "Loss = 0.0148124098777771\n",
      "Loss = 0.0145081402733922\n",
      "Loss = 0.014210142195224762\n",
      "Loss = 0.013918249867856503\n",
      "Loss = 0.013632372952997684\n",
      "Loss = 0.013352357782423496\n",
      "Loss = 0.013078086078166962\n",
      "Loss = 0.012809461914002895\n",
      "Loss = 0.012546341866254807\n",
      "Loss = 0.012288632802665234\n",
      "Loss = 0.012036208063364029\n",
      "Loss = 0.011788983829319477\n",
      "Loss = 0.011546842753887177\n",
      "Loss = 0.01130965631455183\n",
      "Loss = 0.01107735838741064\n",
      "Loss = 0.010849818587303162\n",
      "Loss = 0.010626948438584805\n",
      "Loss = 0.010408666916191578\n",
      "Loss = 0.010194879956543446\n",
      "Loss = 0.009985462762415409\n",
      "Loss = 0.009780356660485268\n",
      "Loss = 0.009579470381140709\n",
      "Loss = 0.009382698684930801\n",
      "Loss = 0.009189973585307598\n",
      "Loss = 0.009001187980175018\n",
      "Loss = 0.008816300891339779\n",
      "Loss = 0.008635207079350948\n",
      "Loss = 0.008457852527499199\n",
      "Loss = 0.00828411616384983\n",
      "Loss = 0.008113951422274113\n",
      "Loss = 0.007947289384901524\n",
      "Loss = 0.007784045767039061\n",
      "Loss = 0.007624173071235418\n",
      "Loss = 0.007467562332749367\n",
      "Loss = 0.00731416791677475\n",
      "Loss = 0.007163938134908676\n",
      "Loss = 0.007016779854893684\n",
      "Loss = 0.006872661877423525\n",
      "Loss = 0.006731489207595587\n",
      "Loss = 0.0065932204015553\n",
      "Loss = 0.0064578005112707615\n",
      "Loss = 0.006325146649032831\n",
      "Loss = 0.0061952280811965466\n",
      "Loss = 0.006067968439310789\n",
      "Loss = 0.005943330470472574\n",
      "Loss = 0.005821256432682276\n",
      "Loss = 0.005701682064682245\n",
      "Loss = 0.00558457151055336\n",
      "Loss = 0.005469858646392822\n",
      "Loss = 0.0053574941121041775\n",
      "Loss = 0.0052474564872682095\n",
      "Loss = 0.005139669869095087\n",
      "Loss = 0.005034098867326975\n",
      "Loss = 0.004930692259222269\n",
      "Loss = 0.0048294225707650185\n",
      "Loss = 0.004730218555778265\n",
      "Loss = 0.00463305227458477\n",
      "Loss = 0.0045378925278782845\n",
      "Loss = 0.004444670397788286\n",
      "Loss = 0.004353380762040615\n",
      "Loss = 0.0042639621533453465\n",
      "Loss = 0.004176370333880186\n",
      "Loss = 0.004090588539838791\n",
      "Loss = 0.004006567876785994\n",
      "Loss = 0.003924263641238213\n",
      "Loss = 0.003843659767881036\n",
      "Loss = 0.0037647110875695944\n",
      "Loss = 0.0036873864009976387\n",
      "Loss = 0.0036116403061896563\n",
      "Loss = 0.0035374544095247984\n",
      "Loss = 0.003464791690930724\n",
      "Loss = 0.0033936260733753443\n",
      "Loss = 0.003323911689221859\n",
      "Loss = 0.003255638061091304\n",
      "Loss = 0.0031887730583548546\n",
      "Loss = 0.0031232675537467003\n",
      "Loss = 0.0030591199174523354\n",
      "Loss = 0.0029962819535285234\n",
      "Loss = 0.0029347380623221397\n",
      "Loss = 0.0028744565788656473\n",
      "Loss = 0.002815404674038291\n",
      "Loss = 0.002757582115009427\n",
      "Loss = 0.0027009372133761644\n",
      "Loss = 0.0026454629842191935\n",
      "Loss = 0.002591121708974242\n",
      "Loss = 0.0025378938298672438\n",
      "Loss = 0.002485761186107993\n",
      "Loss = 0.002434702357277274\n",
      "Loss = 0.002384692197665572\n",
      "Loss = 0.0023357069585472345\n",
      "Loss = 0.0022877322044223547\n",
      "Loss = 0.0022407446522265673\n",
      "Loss = 0.002194714965298772\n",
      "Loss = 0.002149638021364808\n",
      "Loss = 0.0021054777316749096\n",
      "Loss = 0.002062228275462985\n",
      "Loss = 0.0020198700949549675\n",
      "Loss = 0.0019783845636993647\n",
      "Loss = 0.0019377468852326274\n",
      "Loss = 0.001897946815006435\n",
      "Loss = 0.001858963049016893\n",
      "Loss = 0.0018207767279818654\n",
      "Loss = 0.001783374696969986\n",
      "Loss = 0.0017467498546466231\n",
      "Loss = 0.0017108652973547578\n",
      "Loss = 0.001675726962275803\n",
      "Loss = 0.001641301903873682\n",
      "Loss = 0.0016075909370556474\n",
      "Loss = 0.0015745687996968627\n",
      "Loss = 0.0015422273427248001\n",
      "Loss = 0.0015105484053492546\n",
      "Loss = 0.001479524653404951\n",
      "Loss = 0.0014491331530734897\n",
      "Loss = 0.0014193658716976643\n",
      "Loss = 0.001390210003592074\n",
      "Loss = 0.0013616573996841908\n",
      "Loss = 0.001333685009740293\n",
      "Loss = 0.0013062901562079787\n",
      "Loss = 0.0012794643407687545\n",
      "Loss = 0.0012531812535598874\n",
      "Loss = 0.0012274413602426648\n",
      "Loss = 0.00120222894474864\n",
      "Loss = 0.0011775356251746416\n",
      "Loss = 0.0011533439392223954\n",
      "Loss = 0.001129653537645936\n",
      "Loss = 0.0011064495192840695\n",
      "Loss = 0.0010837250156328082\n",
      "Loss = 0.00106146524194628\n",
      "Loss = 0.0010396599536761642\n",
      "Loss = 0.0010183023987337947\n",
      "Loss = 0.0009973858250305057\n",
      "Loss = 0.0009768960298970342\n",
      "Loss = 0.0009568312671035528\n",
      "Loss = 0.000937180535402149\n",
      "Loss = 0.0009179261396639049\n",
      "Loss = 0.000899074599146843\n",
      "Loss = 0.0008806033874861896\n",
      "Loss = 0.00086252047913149\n",
      "Loss = 0.0008448039297945797\n",
      "Loss = 0.0008274512947537005\n",
      "Loss = 0.0008104550070129335\n",
      "Loss = 0.0007938037742860615\n",
      "Loss = 0.0007774997502565384\n",
      "Loss = 0.0007615324575453997\n",
      "Loss = 0.0007458918844349682\n",
      "Loss = 0.0007305694743990898\n",
      "Loss = 0.0007155645289458334\n",
      "Loss = 0.0007008654065430164\n",
      "Loss = 0.000686470593791455\n",
      "Loss = 0.0006723682745359838\n",
      "Loss = 0.000658561650197953\n",
      "Loss = 0.0006450333748944104\n",
      "Loss = 0.0006317817023955286\n",
      "Loss = 0.0006188040715642273\n",
      "Loss = 0.0006060936138965189\n",
      "Loss = 0.0005936478264629841\n",
      "Loss = 0.0005814513424411416\n",
      "Loss = 0.0005695123109035194\n",
      "Loss = 0.0005578121053986251\n",
      "Loss = 0.0005463559064082801\n",
      "Loss = 0.0005351307918317616\n",
      "Loss = 0.0005241372273303568\n",
      "Loss = 0.0005133709055371583\n",
      "Loss = 0.0005028296145610511\n",
      "Loss = 0.0004925007815472782\n",
      "Loss = 0.0004823812923859805\n",
      "Loss = 0.0004724738246295601\n",
      "Loss = 0.00046276964712888\n",
      "Loss = 0.0004532634047791362\n",
      "Loss = 0.00044395201257430017\n",
      "Loss = 0.00043483288027346134\n",
      "Loss = 0.0004259024281054735\n",
      "Loss = 0.00041715253610163927\n",
      "Loss = 0.00040858646389096975\n",
      "Loss = 0.000400191085645929\n",
      "Loss = 0.00039197353180497885\n",
      "Loss = 0.00038392122951336205\n",
      "Loss = 0.00037603251985274255\n",
      "Loss = 0.00036831150646321476\n",
      "Loss = 0.00036074683885090053\n",
      "Loss = 0.0003533367707859725\n",
      "Loss = 0.00034607815905474126\n",
      "Loss = 0.0003389689663890749\n",
      "Loss = 0.00033200872712768614\n",
      "Loss = 0.0003251862362958491\n",
      "Loss = 0.0003185097884852439\n",
      "Loss = 0.0003119669563602656\n",
      "Loss = 0.0003055585839319974\n",
      "Loss = 0.00029928222647868097\n",
      "Loss = 0.0002931330818682909\n",
      "Loss = 0.00028711173217743635\n",
      "Loss = 0.0002812154416460544\n",
      "Loss = 0.00027543731266632676\n",
      "Loss = 0.0002697817690204829\n",
      "Loss = 0.00026424069073982537\n",
      "Loss = 0.0002588106144685298\n",
      "Loss = 0.0002534945379011333\n",
      "Loss = 0.00024828786263242364\n",
      "Loss = 0.00024318852229043841\n",
      "Loss = 0.00023819319903850555\n",
      "Loss = 0.00023330231488216668\n",
      "Loss = 0.00022851035464555025\n",
      "Loss = 0.0002238158485852182\n",
      "Loss = 0.00021922071755398065\n",
      "Loss = 0.00021471579384524375\n",
      "Loss = 0.00021030705829616636\n",
      "Loss = 0.00020598543051164597\n",
      "Loss = 0.00020175652753096074\n",
      "Loss = 0.00019761070143431425\n",
      "Loss = 0.00019355279800947756\n",
      "Loss = 0.00018957546853926033\n",
      "Loss = 0.00018568249652162194\n",
      "Loss = 0.00018186801753472537\n",
      "Loss = 0.00017813484009820968\n",
      "Loss = 0.00017447418940719217\n",
      "Loss = 0.00017089089669752866\n",
      "Loss = 0.00016738002886995673\n",
      "Loss = 0.00016394304111599922\n",
      "Loss = 0.00016057374887168407\n",
      "Loss = 0.00015727715799584985\n",
      "Loss = 0.0001540468801977113\n",
      "Loss = 0.0001508811255916953\n",
      "Loss = 0.00014778246986679733\n",
      "Loss = 0.0001447467366233468\n",
      "Loss = 0.00014177526463754475\n",
      "Loss = 0.00013886367378290743\n",
      "Loss = 0.00013601103273686022\n",
      "Loss = 0.0001332164538325742\n",
      "Loss = 0.00013047900574747473\n",
      "Loss = 0.00012779982353094965\n",
      "Loss = 0.00012517393042799085\n",
      "Loss = 0.0001226021267939359\n",
      "Loss = 0.00012008369230898097\n",
      "Loss = 0.00011761821224354208\n",
      "Loss = 0.0001152037875726819\n",
      "Loss = 0.00011283726780675352\n",
      "Loss = 0.00011051928595406935\n",
      "Loss = 0.00010824832861544564\n",
      "Loss = 0.00010602510155877098\n",
      "Loss = 0.00010384733468526974\n",
      "Loss = 0.00010171434405492619\n",
      "Loss = 9.962578042177483e-05\n",
      "Loss = 9.757931547937915e-05\n",
      "Loss = 9.557574958307669e-05\n",
      "Loss = 9.361255069961771e-05\n",
      "Loss = 9.1689289547503e-05\n",
      "Loss = 8.98061553016305e-05\n",
      "Loss = 8.795998292043805e-05\n",
      "Loss = 8.615365368314087e-05\n",
      "Loss = 8.438451186520979e-05\n",
      "Loss = 8.265028009191155e-05\n",
      "Loss = 8.095232624327764e-05\n",
      "Loss = 7.92903229012154e-05\n",
      "Loss = 7.766066119074821e-05\n",
      "Loss = 7.606665894854814e-05\n",
      "Loss = 7.450333214364946e-05\n",
      "Loss = 7.29742314433679e-05\n",
      "Loss = 7.147534779505804e-05\n",
      "Loss = 7.00060700182803e-05\n",
      "Loss = 6.856772961327806e-05\n",
      "Loss = 6.715987547067925e-05\n",
      "Loss = 6.578093598363921e-05\n",
      "Loss = 6.442845915444195e-05\n",
      "Loss = 6.310528988251463e-05\n",
      "Loss = 6.180817581480369e-05\n",
      "Loss = 6.053921242710203e-05\n",
      "Loss = 5.9296184190316126e-05\n",
      "Loss = 5.8078134316019714e-05\n",
      "Loss = 5.688524470315315e-05\n",
      "Loss = 5.571723522734828e-05\n",
      "Loss = 5.457176303025335e-05\n",
      "Loss = 5.3451502026291564e-05\n",
      "Loss = 5.235284334048629e-05\n",
      "Loss = 5.1277569582453e-05\n",
      "Loss = 5.0224425649503246e-05\n",
      "Loss = 4.9192381993634626e-05\n",
      "Loss = 4.818242814508267e-05\n",
      "tensor([[18.9797]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(nn.Linear(1, 1))\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Prepare data\n",
    "xs = torch.tensor([[-1.0], [0.0], [1.0], [2.0], [3.0], [4.0]], dtype=torch.float32)\n",
    "ys = torch.tensor([[-3.0], [-1.0], [1.0], [3.0], [5.0], [7.0]], dtype=torch.float32)\n",
    "\n",
    "# Training loop\n",
    "for _ in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(xs)\n",
    "    loss = criterion(outputs, ys)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"Loss = \" + str(loss.item()))\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    prediction = model(torch.tensor([[10.0]], dtype=torch.float32))\n",
    "    print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQMjYiLzcr0P",
    "outputId": "991a17a7-c2ff-427b-ccee-7a959431a97b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[1.9970648]]\n",
      "Bias: [-0.9908999]\n"
     ]
    }
   ],
   "source": [
    "# Access the first (and only) layer in the sequential model\n",
    "layer = model[0]\n",
    "\n",
    "# Get weights and bias\n",
    "weights = layer.weight.data.numpy()\n",
    "bias = layer.bias.data.numpy()\n",
    "\n",
    "print(\"Weights:\", weights)\n",
    "print(\"Bias:\", bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
